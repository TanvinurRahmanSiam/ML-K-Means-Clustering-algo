# -*- coding: utf-8 -*-
"""ML _ K Means Clustering_algo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UFptULg22yglkt36FYMylVx7Fexr7WVp

# One of the most widely used unsupervised machine learning algorithms for solving classification problems is K means. K Means divides unlabeled data into clusters based on shared characteristics and patterns.

`To find groups that haven't been explicitly labeled in the data, the K-means clustering algorithm is used. This can be used to verify business assumptions about the types of groups that exist, as well as to identify unknown groups in large data sets.`
"""

from sklearn.cluster import KMeans
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

"""*read_csv is a useful pandas function for reading and manipulating csv files.*"""

df = pd.read_csv("/content/ml k means clustering algo.csv")
df.head(8)

"""*Scatter plots are used to visualize the relationship between variables, with dots representing the relationship. A scatter plot is created using the matplotlib library's scatter() method.*"""

plt.scatter(df['Age'],df['Salary'])

"""`Cluster analysis, also known as clustering, is an unsupervised machine learning method for grouping unlabeled datasets. Its goal is to create clusters or groups from data points in a dataset with high intra-cluster similarity and low inter-cluster similarity.`"""

km_object = KMeans (n_clusters=4)
km_object

"""*Model fitting refers to how well a machine learning model generalizes to data that is similar to the data it was trained on. A well-fitted model generates more accurate results. An overfitted model is one that matches the data too closely. A model that is underfitted does not fit as well as it should.*"""

prediction = km_object.fit_predict(df[['Age','Salary']])
prediction

df['category'] = prediction
df.head(8)

"""`A legend is a section of the graph that describes the various elements. Legend() is a function in the matplotlib library that is used to place a legend on the axes. The legend's location is specified by the attribute in legend().`"""

df1 = df[df.category==0]
df2 = df[df.category==1]
df3 = df[df.category==2]
df4 = df[df.category==3]

plt.scatter(df1.Age, df1['Salary'], color='red')
plt.scatter(df2.Age, df2['Salary'], color='blue')
plt.scatter(df3.Age, df3['Salary'], color='black')
plt.scatter(df4.Age, df4['Salary'], color='violet')

plt.xlabel('Age')
plt.ylabel('Salary')
plt.legend()

"""`The MinMaxscaler scales the minimum and maximum values to 0 and 1, respectively. The StandardScaler, on the other hand, scales all values between min and max to fit within a range of min to max.`

*The fit_transform() function is applied to the training data in order to scale it and learn its scaling parameters. Here, the model we built will learn the mean and variance of the training set's features. Our test data is then scaled using the parameters we've learned.*
"""

scaler = MinMaxScaler()
scaler.fit(df[['Salary']])
df['Salary'] = scaler.transform(df[['Salary']])
df

scaler_new = MinMaxScaler()
scaler_new.fit(df[['Age']])
df.Age = scaler_new.transform (df[['Age']])
df

km_obj_new = KMeans(n_clusters=4)
prediction_new = km_obj_new.fit_predict(df[['Age','Salary']])
prediction_new

df['cluster_new'] = prediction
df.drop('category',axis='columns', inplace=True)
df

df1 = df[df.cluster_new==0]
df2 = df[df.cluster_new==1]
df3 = df[df.cluster_new==2]
df4 = df[df.cluster_new==3]

"""*The "cluster center" is the arithmetic mean of all of the cluster's points. Each point is closer to its own cluster center than it is to the cluster centers of other clusters.*"""

km_obj_new.cluster_centers_

plt.scatter(df1.Age, df1['Salary'], color='red')
plt.scatter(df2.Age, df2['Salary'], color='blue')
plt.scatter(df3.Age, df3['Salary'], color='cyan')
plt.scatter(df4.Age, df4['Salary'], color='violet')

plt.scatter(km_obj_new.cluster_centers_[:,0], km_obj_new.cluster_centers_[:,1], color = 'black', marker='+', label='centroid')

#plt.xlabel('Age')
#plt.ylabel('Salary')
plt.legend()

"""*The elbow method chooses an ideal value of k based on the distance between data points and their assigned clusters using the sum of squared distance (SSE). We'd pick a k value where the SSE starts to flatten out and an inflection point appears.*

`Here, we the "ks" acts as sse(sum of squared distance or error), it will store inside of it's own bag.`
"""

km_elbow = range(1,10)
ks = []
for k in km_elbow:
	km = KMeans(n_clusters=k)
	km.fit(df[['Age','Salary']])
	ks.append(km.inertia_)
ks

plt.xlabel('K')
plt.ylabel('Sum of Squared Error (SSE)')
plt.plot (km_elbow,ks)